{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Install/Import Necessary Libraries"
      ],
      "metadata": {
        "id": "D22TqWgpeHU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q faiss-cpu   # Facebook AI Similarity Search - used for efficient similarity search"
      ],
      "metadata": {
        "id": "TN80umjdSAQV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss    # Facebook AI Similarity Search - used for efficient similarity search\n",
        "import numpy as np  # For numerical operations, especially arrays and matrices\n",
        "import torch   # PyTorch - for loading and running deep learning models\n",
        "from transformers import AutoModel, AutoTokenizer   # Hugging Face transformers for loading pretrained models"
      ],
      "metadata": {
        "id": "XkwLNk21bh8m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Check if GPU is available and use it; otherwise fall back to CPU"
      ],
      "metadata": {
        "id": "rGJJAu36eL7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru_eNqL_bl7D",
        "outputId": "02ec67b3-e6cb-4d4d-e5a2-2541eff71e73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Sample Corpus"
      ],
      "metadata": {
        "id": "_KXW1hUhePEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Chai at Sharma Ji's tea stall in Hazratganj hits different after lectures\",\n",
        "    \"Biryani from Tunday Kababi is a weekend ritual for foodies\",\n",
        "    \"Evening walks at Gomti Riverfront are refreshing after a long day\",\n",
        "    \"Studying in AKTU comes with its own charm\",\n",
        "    \"Assignments are best done the night before deadline\",\n",
        "    \"Gomti Nagar cafes are favorite hangout spots for students\",\n",
        "    \"During exams, everyone suddenly becomes religious\",\n",
        "    \"Street food near Kapoorthala is always buzzing with students\",\n",
        "    \"Hostel life teaches you more than any textbook can\",\n",
        "    \"Python coding becomes fun when done with friends at night\",\n",
        "    \"College fests in Lucknow are full of energy and dance\",\n",
        "    \"Local coaching centers are packed during entrance exam season\",\n",
        "    \"Rainy days in Lucknow make chai and pakoras mandatory\",\n",
        "    \"Instagram reels take more time than actual assignments\",\n",
        "    \"Lucknow students are pros at last-minute exam prep\",\n",
        "    \"The best part of college is hanging out at the campus gate\",\n",
        "    \"Everyone becomes a motivational speaker during exams\"\n",
        "]"
      ],
      "metadata": {
        "id": "n81PaBzGbqsB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HF_TOKEN'] = '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'"
      ],
      "metadata": {
        "id": "YdANAmqzb3S8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Tokenization and Embedding model"
      ],
      "metadata": {
        "id": "15JU5FryeX1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer for the INSTRUCTOR model - this breaks text into tokens for the model to process\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hkunlp/instructor-xl\")\n",
        "# Load the encoder part of the INSTRUCTOR model and move it to GPU/CPU (to generate contextual embeddings)\n",
        "model = AutoModel.from_pretrained(\"hkunlp/instructor-xl\").encoder.to(device)\n",
        "\n",
        "# ignore warnings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPdJ28IIbvHa",
        "outputId": "1a42733b-154b-4b37-ced2-ab88bbf5b2d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
            "Some weights of T5Model were not initialized from the model checkpoint at hkunlp/instructor-xl and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre tokenization step\n",
        "# Prepare instruction + text pairs\n",
        "instruction = \"Represent sentence for semantic similarity\"\n",
        "inputs = [[instruction, text] for text in corpus]\n",
        "\n",
        "\n",
        "# we do this step because\n",
        "# The INSTRUCTOR model is a transformer-based language model developed to generate task-specific sentence embeddings\n",
        "# that means it turns a sentence into a vector that captures the sentence’s meaning with respect to a specific instruction or task."
      ],
      "metadata": {
        "id": "5G_G2J5-b9W8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of instruction + text pairs\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJYmsvzscTrU",
        "outputId": "cba4b253-012a-4beb-8bcd-b60a7653864c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Represent sentence for semantic similarity',\n",
              "  \"Chai at Sharma Ji's tea stall in Hazratganj hits different after lectures\"],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Biryani from Tunday Kababi is a weekend ritual for foodies'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Evening walks at Gomti Riverfront are refreshing after a long day'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Studying in AKTU comes with its own charm'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Assignments are best done the night before deadline'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Gomti Nagar cafes are favorite hangout spots for students'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'During exams, everyone suddenly becomes religious'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Street food near Kapoorthala is always buzzing with students'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Hostel life teaches you more than any textbook can'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Python coding becomes fun when done with friends at night'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'College fests in Lucknow are full of energy and dance'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Local coaching centers are packed during entrance exam season'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Rainy days in Lucknow make chai and pakoras mandatory'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Instagram reels take more time than actual assignments'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Lucknow students are pros at last-minute exam prep'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'The best part of college is hanging out at the campus gate'],\n",
              " ['Represent sentence for semantic similarity',\n",
              "  'Everyone becomes a motivational speaker during exams']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and generate embeddings\n",
        "with torch.no_grad():\n",
        "    # Tokenize the inputs\n",
        "    tokenized_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    # padding=True: Adds padding tokens to shorter sentences so that all sequences are the same length.\n",
        "    # truncation=True: Truncates longer sentences to fit the model’s max input length.\n",
        "    # return_tensors=\"pt\": Returns PyTorch tensors instead of plain lists or NumPy arrays.\n",
        "    # .to(device): Moves the data to GPU (if available) or CPU, depending on earlier device setting.\n",
        "\n",
        "\n",
        "    # Passes the tokenized inputs to the transformer model (to generate embeddings)\n",
        "    outputs = model(**tokenized_inputs)\n",
        "    # selects the first token across all sequences and extracts the embedding corresponding to it\n",
        "    # this token caputures the summary of the entire sentence\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "    # Normalize embeddings\n",
        "    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "    # Convert to numpy array\n",
        "    embeddings = embeddings.cpu().numpy()"
      ],
      "metadata": {
        "id": "UR8sD9SecGH2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQq1WxOgcaDo",
        "outputId": "590a4e91-29b2-4ecd-84a4-52279788d073"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05981033,  0.05593438, -0.01728095, ..., -0.02245244,\n",
              "         0.04297271, -0.0030313 ],\n",
              "       [-0.03933581,  0.06761319, -0.00771267, ..., -0.0242745 ,\n",
              "         0.04034788,  0.00161839],\n",
              "       [-0.05593694,  0.06834757, -0.01870932, ..., -0.01145083,\n",
              "         0.01680318,  0.01874093],\n",
              "       ...,\n",
              "       [-0.06866862,  0.06265455, -0.02622236, ..., -0.0175017 ,\n",
              "         0.04128272,  0.00350707],\n",
              "       [-0.05939035,  0.07108221, -0.01770738, ..., -0.00785265,\n",
              "         0.01533323,  0.01536106],\n",
              "       [-0.04476127,  0.06080019, -0.01977132, ..., -0.01784521,\n",
              "         0.00703757,  0.0265498 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create FAISS Index"
      ],
      "metadata": {
        "id": "fKC8CHBwey4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBCqkYsXcd6J",
        "outputId": "00d89e5b-fd04-4718-8cf9-44e3f43a9639"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<faiss.swigfaiss_avx512.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x7fefe703c630> >"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define a function to generate embeddings for input pairs using the model"
      ],
      "metadata": {
        "id": "2CR1ouv9e2b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to query the index\n",
        "def search_faiss(query, top_k=3):\n",
        "    # Tokenize and encode the query\n",
        "    with torch.no_grad():\n",
        "        # tokenize the query\n",
        "        tokenized_query = tokenizer([[instruction, query]], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        # generate query embedding\n",
        "        query_output = model(**tokenized_query)\n",
        "        query_vector = query_output.last_hidden_state[:, 0, :]\n",
        "        query_vector = torch.nn.functional.normalize(query_vector, p=2, dim=1)\n",
        "        query_vector = query_vector.cpu().numpy()\n",
        "\n",
        "    # Search the index\n",
        "    scores, indices = index.search(query_vector, top_k)\n",
        "    print(f\"\\nQuery: {query}\\n\")\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        print(f\"{i+1}. {corpus[idx]} (Score: {scores[0][i]:.4f})\")"
      ],
      "metadata": {
        "id": "8V-Le6mFcj8X"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Example search"
      ],
      "metadata": {
        "id": "W03vrhZ2fHAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query\n",
        "search_faiss(\"Where do students relax in Lucknow?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdYSUvJRbM2y",
        "outputId": "d9e31e64-bb22-4952-a779-00f7069d9e17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Where do students relax in Lucknow?\n",
            "\n",
            "1. College fests in Lucknow are full of energy and dance (Score: 0.9080)\n",
            "2. Gomti Nagar cafes are favorite hangout spots for students (Score: 0.9011)\n",
            "3. Street food near Kapoorthala is always buzzing with students (Score: 0.8970)\n"
          ]
        }
      ]
    }
  ]
}
